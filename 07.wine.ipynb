{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4ad072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970c8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv('media/wine.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cef29ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>5.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>33.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99440</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.13</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.036</td>\n",
       "      <td>49.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.99960</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.045</td>\n",
       "      <td>54.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.080</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.038</td>\n",
       "      <td>43.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99924</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.41</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3      4     5      6        7     8     9    10  11  \\\n",
       "1870  5.2  0.60  0.07   7.0  0.044  33.0  147.0  0.99440  3.33  0.58  9.7   5   \n",
       "3549  8.0  0.25  0.13  17.2  0.036  49.0  219.0  0.99960  2.96  0.46  9.7   5   \n",
       "4657  6.2  0.25  0.38   7.9  0.045  54.0  208.0  0.99572  3.17  0.46  9.1   5   \n",
       "123   8.0  0.71  0.00   2.6  0.080  11.0   34.0  0.99760  3.44  0.53  9.5   5   \n",
       "4300  6.5  0.23  0.36  16.3  0.038  43.0  133.0  0.99924  3.26  0.41  8.8   5   \n",
       "\n",
       "      12  \n",
       "1870   0  \n",
       "3549   0  \n",
       "4657   0  \n",
       "123    1  \n",
       "4300   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_pre.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6d5818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6497 entries, 1870 to 1282\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 710.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e20ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "X = dataset[:, 0:12].astype(float)\n",
    "y = dataset[:, 12].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8cb0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d8125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae302db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51cfe98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8792fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7590\n",
      "Epoch 2/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8995\n",
      "Epoch 3/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9227\n",
      "Epoch 4/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.9244\n",
      "Epoch 5/200\n",
      "33/33 [==============================] - 0s 1000us/step - loss: 0.2210 - accuracy: 0.9281\n",
      "Epoch 6/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.2131 - accuracy: 0.9298\n",
      "Epoch 7/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.2078 - accuracy: 0.9327\n",
      "Epoch 8/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.2004 - accuracy: 0.9326\n",
      "Epoch 9/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.94 - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9341\n",
      "Epoch 10/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9354\n",
      "Epoch 11/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.1818 - accuracy: 0.9358\n",
      "Epoch 12/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1779 - accuracy: 0.9386\n",
      "Epoch 13/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1731 - accuracy: 0.9390\n",
      "Epoch 14/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.1699 - accuracy: 0.9392\n",
      "Epoch 15/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.1647 - accuracy: 0.9421\n",
      "Epoch 16/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.1624 - accuracy: 0.9427\n",
      "Epoch 17/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1610 - accuracy: 0.9423\n",
      "Epoch 18/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9423\n",
      "Epoch 19/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.1503 - accuracy: 0.9451\n",
      "Epoch 20/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1466 - accuracy: 0.9463\n",
      "Epoch 21/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.1435 - accuracy: 0.9471\n",
      "Epoch 22/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1367 - accuracy: 0.9492\n",
      "Epoch 23/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.1328 - accuracy: 0.9512\n",
      "Epoch 24/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1289 - accuracy: 0.9509\n",
      "Epoch 25/200\n",
      "33/33 [==============================] - 0s 1000us/step - loss: 0.1256 - accuracy: 0.9546\n",
      "Epoch 26/200\n",
      "33/33 [==============================] - 0s 1000us/step - loss: 0.1236 - accuracy: 0.9557\n",
      "Epoch 27/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1170 - accuracy: 0.9575\n",
      "Epoch 28/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.1167 - accuracy: 0.9572\n",
      "Epoch 29/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9609\n",
      "Epoch 30/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1082 - accuracy: 0.9638\n",
      "Epoch 31/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.1073 - accuracy: 0.9626\n",
      "Epoch 32/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.1042 - accuracy: 0.9655\n",
      "Epoch 33/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.1038 - accuracy: 0.9641\n",
      "Epoch 34/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0991 - accuracy: 0.9683\n",
      "Epoch 35/200\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.0971 - accuracy: 0.9703\n",
      "Epoch 36/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0983 - accuracy: 0.9677\n",
      "Epoch 37/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0994 - accuracy: 0.9684\n",
      "Epoch 38/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0910 - accuracy: 0.9721\n",
      "Epoch 39/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0894 - accuracy: 0.9714\n",
      "Epoch 40/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0891 - accuracy: 0.9712\n",
      "Epoch 41/200\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.97 - 0s 1ms/step - loss: 0.0868 - accuracy: 0.9734\n",
      "Epoch 42/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0883 - accuracy: 0.9708\n",
      "Epoch 43/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0876 - accuracy: 0.9731\n",
      "Epoch 44/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.9698\n",
      "Epoch 45/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9746\n",
      "Epoch 46/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.0819 - accuracy: 0.9737\n",
      "Epoch 47/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0818 - accuracy: 0.9735\n",
      "Epoch 48/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0814 - accuracy: 0.9746\n",
      "Epoch 49/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.0780 - accuracy: 0.9754\n",
      "Epoch 50/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0791 - accuracy: 0.9748\n",
      "Epoch 51/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0783 - accuracy: 0.9765\n",
      "Epoch 52/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0755 - accuracy: 0.9761\n",
      "Epoch 53/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0773 - accuracy: 0.9766\n",
      "Epoch 54/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0737 - accuracy: 0.9774\n",
      "Epoch 55/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0744 - accuracy: 0.9769\n",
      "Epoch 56/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0747 - accuracy: 0.9775\n",
      "Epoch 57/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0723 - accuracy: 0.9786\n",
      "Epoch 58/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0787 - accuracy: 0.9751\n",
      "Epoch 59/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0739 - accuracy: 0.9760\n",
      "Epoch 60/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0754 - accuracy: 0.9760\n",
      "Epoch 61/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0745 - accuracy: 0.9777\n",
      "Epoch 62/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0733 - accuracy: 0.9769\n",
      "Epoch 63/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0718 - accuracy: 0.9775\n",
      "Epoch 64/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0692 - accuracy: 0.9786\n",
      "Epoch 65/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0662 - accuracy: 0.9797\n",
      "Epoch 66/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0727 - accuracy: 0.9766\n",
      "Epoch 67/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0711 - accuracy: 0.9788\n",
      "Epoch 68/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0702 - accuracy: 0.9781\n",
      "Epoch 69/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0680 - accuracy: 0.9803\n",
      "Epoch 70/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0687 - accuracy: 0.9798\n",
      "Epoch 71/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0655 - accuracy: 0.9798\n",
      "Epoch 72/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0655 - accuracy: 0.9795\n",
      "Epoch 73/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0644 - accuracy: 0.9808\n",
      "Epoch 74/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0639 - accuracy: 0.9815\n",
      "Epoch 75/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0700 - accuracy: 0.9775\n",
      "Epoch 76/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0635 - accuracy: 0.9803\n",
      "Epoch 77/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0661 - accuracy: 0.9806\n",
      "Epoch 78/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0616 - accuracy: 0.9812\n",
      "Epoch 79/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0655 - accuracy: 0.9803\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 909us/step - loss: 0.0637 - accuracy: 0.9811\n",
      "Epoch 81/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0611 - accuracy: 0.9808\n",
      "Epoch 82/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0619 - accuracy: 0.9808\n",
      "Epoch 83/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0647 - accuracy: 0.9791\n",
      "Epoch 84/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0600 - accuracy: 0.9817\n",
      "Epoch 85/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0603 - accuracy: 0.9818\n",
      "Epoch 86/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0599 - accuracy: 0.9812\n",
      "Epoch 87/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0652 - accuracy: 0.9789\n",
      "Epoch 88/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0597 - accuracy: 0.9829\n",
      "Epoch 89/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9795\n",
      "Epoch 90/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.9786\n",
      "Epoch 91/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9805\n",
      "Epoch 92/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0684 - accuracy: 0.9789\n",
      "Epoch 93/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9823\n",
      "Epoch 94/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 0.9815\n",
      "Epoch 95/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0576 - accuracy: 0.9826\n",
      "Epoch 96/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0587 - accuracy: 0.9826\n",
      "Epoch 97/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0587 - accuracy: 0.9829\n",
      "Epoch 98/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9828\n",
      "Epoch 99/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9785\n",
      "Epoch 100/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9826\n",
      "Epoch 101/200\n",
      "33/33 [==============================] - 0s 727us/step - loss: 0.0582 - accuracy: 0.9820\n",
      "Epoch 102/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0569 - accuracy: 0.9825\n",
      "Epoch 103/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0632 - accuracy: 0.9791\n",
      "Epoch 104/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0594 - accuracy: 0.9832\n",
      "Epoch 105/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0595 - accuracy: 0.9832\n",
      "Epoch 106/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9837\n",
      "Epoch 107/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9837\n",
      "Epoch 108/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9832\n",
      "Epoch 109/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9821\n",
      "Epoch 110/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9832\n",
      "Epoch 111/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0605 - accuracy: 0.9820\n",
      "Epoch 112/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0593 - accuracy: 0.9817\n",
      "Epoch 113/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0574 - accuracy: 0.9821\n",
      "Epoch 114/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0594 - accuracy: 0.9831\n",
      "Epoch 115/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0607 - accuracy: 0.9801\n",
      "Epoch 116/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0600 - accuracy: 0.9809\n",
      "Epoch 117/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0592 - accuracy: 0.9811\n",
      "Epoch 118/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0575 - accuracy: 0.9834\n",
      "Epoch 119/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0544 - accuracy: 0.9843\n",
      "Epoch 120/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0641 - accuracy: 0.9791\n",
      "Epoch 121/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0560 - accuracy: 0.9832\n",
      "Epoch 122/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0615 - accuracy: 0.9817\n",
      "Epoch 123/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9838\n",
      "Epoch 124/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9831\n",
      "Epoch 125/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9820\n",
      "Epoch 126/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0545 - accuracy: 0.9841\n",
      "Epoch 127/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9840\n",
      "Epoch 128/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0565 - accuracy: 0.9840\n",
      "Epoch 129/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0563 - accuracy: 0.9841\n",
      "Epoch 130/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0534 - accuracy: 0.9852\n",
      "Epoch 131/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9828\n",
      "Epoch 132/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9828\n",
      "Epoch 133/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 134/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0589 - accuracy: 0.9823\n",
      "Epoch 135/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0533 - accuracy: 0.9845\n",
      "Epoch 136/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0569 - accuracy: 0.9818\n",
      "Epoch 137/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0533 - accuracy: 0.9841\n",
      "Epoch 138/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0551 - accuracy: 0.9841\n",
      "Epoch 139/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9834\n",
      "Epoch 140/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9834\n",
      "Epoch 141/200\n",
      "33/33 [==============================] - 0s 1000us/step - loss: 0.0546 - accuracy: 0.9843\n",
      "Epoch 142/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0532 - accuracy: 0.9834\n",
      "Epoch 143/200\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.0529 - accuracy: 0.9851\n",
      "Epoch 144/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0528 - accuracy: 0.9841\n",
      "Epoch 145/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0565 - accuracy: 0.9838\n",
      "Epoch 146/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9834\n",
      "Epoch 147/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.0540 - accuracy: 0.9832\n",
      "Epoch 148/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0543 - accuracy: 0.9838\n",
      "Epoch 149/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0547 - accuracy: 0.9840\n",
      "Epoch 150/200\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.0552 - accuracy: 0.9832\n",
      "Epoch 151/200\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.0535 - accuracy: 0.9848\n",
      "Epoch 152/200\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.0543 - accuracy: 0.9829\n",
      "Epoch 153/200\n",
      "33/33 [==============================] - 0s 667us/step - loss: 0.0561 - accuracy: 0.9828\n",
      "Epoch 154/200\n",
      "33/33 [==============================] - 0s 636us/step - loss: 0.0563 - accuracy: 0.9841\n",
      "Epoch 155/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0540 - accuracy: 0.9832\n",
      "Epoch 156/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0640 - accuracy: 0.9786\n",
      "Epoch 157/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0571 - accuracy: 0.9826\n",
      "Epoch 158/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0520 - accuracy: 0.9826\n",
      "Epoch 159/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0531 - accuracy: 0.9843\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 788us/step - loss: 0.0528 - accuracy: 0.9843\n",
      "Epoch 161/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0522 - accuracy: 0.9851\n",
      "Epoch 162/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0512 - accuracy: 0.9848\n",
      "Epoch 163/200\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.0556 - accuracy: 0.9821\n",
      "Epoch 164/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0511 - accuracy: 0.9840\n",
      "Epoch 165/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0512 - accuracy: 0.9838\n",
      "Epoch 166/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0519 - accuracy: 0.9846\n",
      "Epoch 167/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0616 - accuracy: 0.9808\n",
      "Epoch 168/200\n",
      "33/33 [==============================] - 0s 758us/step - loss: 0.0557 - accuracy: 0.9841\n",
      "Epoch 169/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0526 - accuracy: 0.9854\n",
      "Epoch 170/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0516 - accuracy: 0.9841\n",
      "Epoch 171/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0596 - accuracy: 0.9814\n",
      "Epoch 172/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0503 - accuracy: 0.9846\n",
      "Epoch 173/200\n",
      "33/33 [==============================] - 0s 909us/step - loss: 0.0525 - accuracy: 0.9851\n",
      "Epoch 174/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0500 - accuracy: 0.9863\n",
      "Epoch 175/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0539 - accuracy: 0.9838\n",
      "Epoch 176/200\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.0652 - accuracy: 0.9777\n",
      "Epoch 177/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0572 - accuracy: 0.9832\n",
      "Epoch 178/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 179/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0501 - accuracy: 0.9845\n",
      "Epoch 180/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0495 - accuracy: 0.9857\n",
      "Epoch 181/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0559 - accuracy: 0.9841\n",
      "Epoch 182/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0654 - accuracy: 0.9788\n",
      "Epoch 183/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0509 - accuracy: 0.9840\n",
      "Epoch 184/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0520 - accuracy: 0.9838\n",
      "Epoch 185/200\n",
      "33/33 [==============================] - 0s 849us/step - loss: 0.0497 - accuracy: 0.9861\n",
      "Epoch 186/200\n",
      "33/33 [==============================] - 0s 788us/step - loss: 0.0523 - accuracy: 0.9837\n",
      "Epoch 187/200\n",
      "33/33 [==============================] - 0s 757us/step - loss: 0.0495 - accuracy: 0.9852\n",
      "Epoch 188/200\n",
      "33/33 [==============================] - 0s 818us/step - loss: 0.0514 - accuracy: 0.9848\n",
      "Epoch 189/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0492 - accuracy: 0.9846\n",
      "Epoch 190/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0490 - accuracy: 0.9866\n",
      "Epoch 191/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0484 - accuracy: 0.9861\n",
      "Epoch 192/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9858\n",
      "Epoch 193/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9820\n",
      "Epoch 194/200\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9854\n",
      "Epoch 195/200\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9823\n",
      "Epoch 196/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9855\n",
      "Epoch 197/200\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9852\n",
      "Epoch 198/200\n",
      "33/33 [==============================] - 0s 939us/step - loss: 0.0502 - accuracy: 0.9852\n",
      "Epoch 199/200\n",
      "33/33 [==============================] - 0s 848us/step - loss: 0.0489 - accuracy: 0.9860\n",
      "Epoch 200/200\n",
      "33/33 [==============================] - 0s 879us/step - loss: 0.0487 - accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eb8c117760>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "defd3116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 897us/step - loss: 0.0478 - accuracy: 0.9868\n",
      "\n",
      " Accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X,y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705b9fb",
   "metadata": {},
   "source": [
    "# - 모델 업데이트하기 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02d58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b307e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1691844",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "372ddda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04877, saving model to ./model\\01-0.0488.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04877 to 0.04719, saving model to ./model\\02-0.0472.hdf5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04719\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04719 to 0.04661, saving model to ./model\\04-0.0466.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04661 to 0.04555, saving model to ./model\\05-0.0455.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04555\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04555 to 0.04539, saving model to ./model\\42-0.0454.hdf5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.04539\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04539 to 0.04490, saving model to ./model\\56-0.0449.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.04490\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.04490\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.04490\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.04490\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.04490 to 0.04463, saving model to ./model\\61-0.0446.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.04463\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.04463 to 0.04438, saving model to ./model\\74-0.0444.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.04438\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.04438 to 0.04414, saving model to ./model\\84-0.0441.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.04414\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.04414\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.04414\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.04414 to 0.04385, saving model to ./model\\88-0.0438.hdf5\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.04385\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.04385\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.04385\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.04385 to 0.04349, saving model to ./model\\92-0.0435.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.04349\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.04349 to 0.04347, saving model to ./model\\111-0.0435.hdf5\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.04347\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.04347 to 0.04320, saving model to ./model\\117-0.0432.hdf5\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.04320\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.04320\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.04320\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.04320 to 0.04289, saving model to ./model\\121-0.0429.hdf5\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.04289\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.04289\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.04289\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.04289\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.04289 to 0.04256, saving model to ./model\\126-0.0426.hdf5\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.04256\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.04256\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.04256\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.04256\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.04256 to 0.04236, saving model to ./model\\131-0.0424.hdf5\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.04236\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.04236 to 0.04164, saving model to ./model\\133-0.0416.hdf5\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.04164\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.04164 to 0.04152, saving model to ./model\\143-0.0415.hdf5\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.04152\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.04152\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.04152\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.04152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00148: val_loss did not improve from 0.04152\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.04152\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.04152 to 0.04058, saving model to ./model\\150-0.0406.hdf5\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.04058\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.04058\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.04058\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.04058\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.04058 to 0.04039, saving model to ./model\\155-0.0404.hdf5\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.04039\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.04039 to 0.04028, saving model to ./model\\169-0.0403.hdf5\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.04028\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.04028\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.04028 to 0.03996, saving model to ./model\\172-0.0400.hdf5\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.03996\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.03996\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.03996 to 0.03990, saving model to ./model\\175-0.0399.hdf5\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.03990\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.03990\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.03990\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.03990\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.03990\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.03990 to 0.03870, saving model to ./model\\181-0.0387.hdf5\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.03870\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.03870 to 0.03829, saving model to ./model\\190-0.0383.hdf5\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.03829\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.03829 to 0.03777, saving model to ./model\\199-0.0378.hdf5\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.03777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eb8d66c400>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1e896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 549us/step - loss: 0.0450 - accuracy: 0.9843\n",
      "\n",
      " Accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X,y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6570594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
